DOCKER - DEEP DIVE



------
Installing DOCKER ::

Add the Utilities needed for Docker: 

  # sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2


Set up the stable repository:
  
  # sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo


 Install Docker CE:

   # sudo yum -y install docker-ce ; sudo systemctl start docker && sudo systemctl enable docker 


  Add cloud_user to the docker group:

    # sudo usermod -aG docker cloud_user



  ---------


  DOCKER UNDER THE HOOD:



Architecture Overview

Docker architecture:

Client-server architecture
Client talks to the Docker daemon

The Docker daemon handles:
Building
Running
Distributing

Both communicate using a REST API:
UNIX sockets
Network interface




The Docker daemon (dockerd):

Listens for Docker API requests and manages Docker objects:
Images
Containers
Networks
Volumes



The Docker client (docker):

Is how users interact with Docker
Sends commands to dockerd


Docker registries:

Stores Docker images
Public registry such as DockerHub
Let you run your own private registry



Docker objects:

Images:
Read-only template with instructions for creating a Docker container
Image is based on another image
Create your own images
Use images published to a registry
Use a Dockerfile to build images

Containers:
Runnable instance of an image
Connect a container to networks
Attach storage
Create a new image based on its current state
Isolated from other containers and the host machine
Services
Scale containers across multiple Docker daemons
Docker Swarm
Define the desired state
Service is load-balanced

Docker Swarm:

Multiple Docker daemons (Master and Workers)
The daemons all communicate using the Docker API
Supported in Docker 1.12 and higher




---------


THE DOCKER ENGINE


Under The Hood
Docker engine:

Modular in design:
Batteries included but replaceable
Based on open-standards outline by the Open Container Initiative
The major components:
Docker client
Docker daemon
containerd
runc

The components work together to create and run containers


A Brief History of the Docker Engine
The first release of Docker:

The Docker daemon:
Monolithic binary
Docker client
Docker API
Container runtime
Image builds
Much more...
LXC:
Namespaces
Control groups (cgroups)
Linux-specific
Refactoring of the Docker Engine
LXC was later replaced with libcontainer:

Docker 0.9
Platform agnostic
Issues with the monolithic Docker daemon:

Harder to innovate
Slow
Not what the ecosystem wanted


Docker became more modular:

Smaller more specialized tools
Pluggable architecture


Open Container Initiative:

Image spec
Container runtime spec
Version 1.0 release in 2017
Docker Inc. heavily contributed
Docker 1.11 (2016) used the specification as much as possible


runc:

Implemenation of the OCI container-runtime-spec
Lightweght CLI wrapper for libcontainer
Create containers


containerd:

Manages container lifecycle
Start
Stop
Pause
Delete
Image management
Part of the 1.11 release


shim:

Implemenation of daemonless Containers
containerd forks an instance of runc for each new container
runc process exits after the container is created
shim process becomes the container parent

Responsible for:
STDIN and STDOUT
Reporting exit status to the Docker daemon
Running Containers
docker container run -it --name <NAME> <IMAGE>:<TAG>


Creating a container:

CLI use for executing a command
Docker client uses the appropriate API payload
POSTs to the correct API endpoint
Docker deamon receives instructions
Docker deamon calls containerd to start a new container
Docker daemon uses gRPC (a CRUD style API)
containerd creates an OCI bundle from the Docker image
Tells runc to create a container using the OCI bundle
runc interfaces with the OS kernal to get the constructs needed to create a container
This includes namespaces, cgroups, etc.
Container process starts as a child process
runc exits once the container starts
Process is complete, and container is running








---------


DOCKER IMAGES AND CONTAINERS:


What are Docker images?

Docker Images:

Files comprised of multiple layers
Execute code in a Docker container
Built from the instructions
Use images to create an instance of a container
Docker images and layers
Image are made of multiple layers.
Each layer represents an instruction in the image’s Dockerfile.
Each layer except, the very last one, is read-only.
Each layer is only a set of differences from the layer before it.
Layers are stacked on top of each other.
Containers add new writable layers on top of the underlying layers
All changes made to a running container is made to the Container layer

What are containers?
A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another.

Container and layers
Top writable layer
All changes are stored in the writable layer
The writable layer is deleted when the container is deleted
The image remains unchanged






----------


DOCKER HUB:
What is Docker Hub?


Public Docker registry
Provided by Docker
Features:
Repositories
Teams and Organizations
Official Images
Publisher Images
Builds
Webhooks
https://hub.docker.com/signup



--------

DOCKER COMMANDS :

Management command were introduced in Docker engine v1.13

Management Commands:

builder---> Manage builds
config---> Manage Docker configs
container---> Manage containers
engine---> Manage the docker engine
image---> Manage images
network---> Manage networks
node---> Manage Swarm nodes
plugin---> Manage plugins
secret---> Manage Docker secrets
service---> Manage services
stack---> Manage Docker stacks
swarm---> Manage Swarm
system---> Manage Docker
trust---> Manage trust on Docker images
volume---> Manage volumes





docker image Commands :


build---> Build an image from a dockerfile  # docker image build --help
history---> Show the history of an image
import---> Import the contents from a tarball to create a filesystem image
inspect---> Display detailed information on one or more images
load---> Load an image from a tar file or STDIN
ls---> List images
prune---> Remove unused images
pull---> Pull an image or a repository from a registry
push---> Push an image or a repository to a registry
rm---> Remove one or more images
save---> Save one or more images to a tar file (streamed to STDOUT by default)
tag---> Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE



TO GET THE DETAILED INFO  -- # docker image build --help


Usage:  docker image build [OPTIONS] PATH | URL | -
Build an image from a Dockerfile
Options:
      --add-host list           Add a custom host-to-IP mapping (host:ip)
      --build-arg list          Set build-time variables
      --cache-from strings      Images to consider as cache sources
      --cgroup-parent string    Optional parent cgroup for the container
      --compress                Compress the build context using gzip
      --cpu-period int          Limit the CPU CFS (Completely Fair Scheduler) period
      --cpu-quota int           Limit the CPU CFS (Completely Fair Scheduler) quota
  -c, --cpu-shares int          CPU shares (relative weight)
      --cpuset-cpus string      CPUs in which to allow execution (0-3, 0,1)
      --cpuset-mems string      MEMs in which to allow execution (0-3, 0,1)
      --disable-content-trust   Skip image verification (default true)
  -f, --file string             Name of the Dockerfile (Default is 'PATH/Dockerfile')
      --force-rm                Always remove intermediate containers
      --iidfile string          Write the image ID to the file
      --isolation string        Container isolation technology
      --label list              Set metadata for an image
  -m, --memory bytes            Memory limit
      --memory-swap bytes       Swap limit equal to memory plus swap: '-1' to enable unlimited swap
      --network string          Set the networking mode for the RUN instructions during build (default "default")
      --no-cache                Do not use cache when building the image
      --pull                    Always attempt to pull a newer version of the image
  -q, --quiet                   Suppress the build output and print image ID on success
      --rm                      Remove intermediate containers after a successful build (default true)
      --security-opt strings    Security options
      --shm-size bytes          Size of /dev/shm
  -t, --tag list                Name and optionally a tag in the 'name:tag' format
      --target string           Set the target build stage to build.
      --ulimit ulimit           Ulimit options (default [])







docker container commands:

attach---> Attach local standard input, output, and error streams to a running container
commit---> Create a new image from a container's changes
cp---> Copy files/folders between a container and the local filesystem
create---> Create a new container
diff---> Inspect changes to files or directories on a container's filesystem
exec---> Run a command in a running container
export---> Export a container's filesystem as a tar archive
inspect---> Display detailed information on one or more containers
kill---> Kill one or more running containers
logs---> Fetch the logs of a container
ls---> List containers
pause---> Pause all processes within one or more containers
port---> List port mappings or a specific mapping for the container
prune---> Remove all stopped containers
rename---> Rename a container
restart---> Restart one or more containers
rm---> Remove one or more containers
run---> Run a command in a new container
start---> Start one or more stopped containers
stats---> Display a live stream of container(s) resource usage statistics
stop---> Stop one or more running containers
top---> Display the running processes of a container
unpause---> Unpause all processes within one or more containers
update---> Update configuration of one or more containers
wait---> Block until one or more containers stop, then print their exit codes






----

CREATING CONTAINERS :

In this lesson, we will take a deeper look into creating containers, by exploring a few of the flags that will alter it's behavior when created.

docker container run:

--help Print usage
--rm Automatically remove the container when it exits
-d, --detach Run container in background and print container ID
-i, --interactive Keep STDIN open even if not attached
--name string Assign a name to the container
-p, --publish list Publish a container's port(s) to the host
-t, --tty Allocate a pseudo-TTY
-v, --volume list Mount a volume (the bind type of mount)
--mount mount Attach a filesystem mount to the container
--network string Connect a container to a network (default "default")

Create a container and attach to it:
 #docker container run –it busybox

Create a container and run it in the background:
 #docker container run –d nginx

Create a container that you name and run it in the background:
 #docker container run –d –name myContainer busybox




------


EXECUTING CONTAINER COMMANDS:

 we'll see three different ways to execute commands on containers.

Executing a command:

Dockerfile
During a Docker run
Using the exec command
Commands can be:

One and done Commands
Long running Commands
Start a container with a command:

docker container run [IMAGE] [CMD]
Execute a command on a container:

docker container exec -it [NAME] [CMD]
Example:

docker container run -d -p 8080:80 nginx
docker container ps
docker container exec -it [NAME] /bin/bash
docker container exec -it [NAME] ls /usr/share/nginx/html/





---------

EXPOSING CONTAINER PORTS:


Building on what we've already learned, this lesson will focus on exposing ports on a container, as well as how to publish them.

EXPOSING:

Expose a port or a range of ports
This does not publish the port
Use --expose [PORT]
docker container run --expose 1234 [IMAGE]


PUBLISHING:

Maps a container's port to a host`s port
-p or --publish publishes a container's port(s) to the host
-P, or --publish-all publishes all exposed ports to random ports





docker container run -p [HOST_PORT]:[CONTAINER_PORT] [IMAGE]

$ docker container run -d --expose 3000 -p 80:3000 nginx



docker container run -p [HOST_PORT]:[CONTAINER_PORT]/tcp -p [HOST_PORT]:[CONTAINER_PORT]/udp [IMAGE]

$ docker container run -d -p 8081:80/tcp -p 8081:80/udp 



-P, or --publish-all publishes all exposed ports to random p

$ docker container run -P nginx 



Lists all port mappings or a specific mapping for a container:


docker container port [Container_NAME] 

$ docker container port 2505acc8d937 
80/tcp -> 0.0.0.0:8081
80/udp -> 0.0.0.0:8081





-------


DOCKER LOGGING :



Container Logging
In this lesson, you will learn how to view the logs of a container to get vital output of your application. You will also learn about some of the logging best practices of containerized applications.

Create a container using the weather-app image.

docker container run --name weather-app -d -p 80:3000 linuxacademycontent/weather-app


Show information logged by a running container:

docker container logs [NAME]

   $ docker container logs 39e6efc6121d
     Listening on port 3000
     GET / 200 31.809 ms - 619
     GET /stylesheets/style.css 200 8.425 ms - 1649
     GET /favicon.ico 404 2.607 ms - 771
     Found weather data for chennai.
     POST / 200 208.875 ms - 679
     GET /stylesheets/style.css 304 1.329 ms - -
     Found weather data for SALEM.
     POST / 200 155.700 ms - 677
     GET /stylesheets/style.css 304 1.285 ms - -
     No weather data was avalable for 121323.
     POST / 200 510.746 ms - 670
     GET /stylesheets/style.css 304 0.421 ms - -
     Show information logged by all containers participating in a service:


     
docker service logs [SERVICE]
Logs need to be output to STDOUT and STDERR.

Nginx Example:

RUN ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log


Debug a failed container deploy:

docker container run -d --name ghost_blog \
-e database__client=mysql \
-e database__connection__host=mysql \
-e database__connection__user=root \
-e database__connection__password=P4sSw0rd0! \
-e database__connection__database=ghost \
-p 8080:2368 \
ghost:1-alpine



USEFUL LINKS:

12 Factor Logs     https://12factor.net/logs
Weather App Code   https://github.com/linuxacademy/content-intermediate-docker-quest/tree/logging
Ruby Logging       https://ruby-doc.org/stdlib-2.6/libdoc/logger/rdoc/Logger.html
Python Logging     https://docs.python.org/2/howto/logging.html





------

NETWORKING OVERVIEW:


we will go over the components and theory of how networking functions in Docker.

Docker Networking 101

DOCKER NETWORKING:

Open-source pluggable architecture

Container Network Model (CNM) - outline the buliding blocks

libnetwork implements CNM - realworld implementation of docker. Also this is uses docker using connecting container and its response for egress.load balancing.. etc

Drivers extend the network topologies


NETWORK DRIVERS:

bridge - It default,link layer network provides traffic bt network segments. provides isolation from other network,  its works on linux.
host   - 
overlay - distribute n/w on swarm
macvlan - allows u to assign mac address to container.
none     - to diasble network, we can't use in swarm
Network plugins - we can use third party network drivers



Container Network Model


DEFINES THREE BUILDING BLOCKS:

Sandboxes - isolates network stack, route and dns
Endpoints - virtual network interface.
Networks - 



-----

NETWORKING BASICS


ifconfig


LIST ALL DOCKER NETWORK COMMANDS:

docker network -h
connect Connect a container to a network create Create a network disconnect Disconnect a container from a network inspect Display detailed information on one or more networks ls List networks prune Remove all unused networks rm Remove one or more networks

LIST ALL DOCKER NETWORKS ON THE HOST:

docker network ls
docker network ls --no-trunc


GETTING DETAILED INFO ON A NETWORK:

docker network inspect [NAME]


CREATING A NETWORK:

docker network create br00


DELETING A NETWORK:

docker network rm [NAME]

Remove all unused networks:

docker network prune



Adding and Removing containers to a network

CREATE A CONTAINER WITH NO NETWORK:

# docker container run -d --name network-test03 -p 8081:80 nginx



CREATE A NEW NETWORK:
                                                 
# docker network create br01


ADD THE CONTAINER TO THE BRIDGE NETWORK:

#docker network connect br01 network-test03


INSPECT NETWORK-TEST03 TO SEE THE NETWORKS:

#docker container inspect network-test03


REMOVE NETWORK-TEST03 FROM BR01:

# docker network disconnect br01 network-test03



-----

NETWORKING CONTAINERS:

 we will dig deeper into container networking by supplying our own subnet and gateway when creating a new network. We will then move on to networking two different containers using an internal network. This will allow one container to be publicly accessible while the other one is not.

CREATING A NETWORK AND DEFINING A SUBNET AND GATEWAY
CREATE A BRIDGE NETWORK WITH A SUBNET AND GATEWAY:

docker network create --subnet 10.1.0.0/24 --gateway 10.1.0.1 br02


RUN IFCONFIG TO VIEW THE BRIDGE INTERFACE FOR BR02:

ifconfig

INSPECT THE BR02 NETWORK:

docker network inspect br02

PRUNE ALL UNUSED NETWORKS:

docker network prune

CREATE A NETWORK WITH AN IP RANGE:

docker network create --subnet 10.1.0.0/16 --gateway 10.1.0.1 \
--ip-range=10.1.4.0/24 --driver=bridge --label=host4network br04

INSPECT THE BR04 NETWORK:

docker network inspect br04

CREATE A CONTAINER USING THE BR04 NETWORK:

docker container run --name network-test01 -it --network br04 centos /bin/bash

INSTALL NET TOOLS:

yum update -y
yum install -y net-tools

GET THE IP INFO FOR THE CONTAINER:

ifconfig

GET THE GATEWAY INFO THE CONTAINER:

netstat -rn

GET THE DNS INFO FOR THE CONTAINER:

cat /etc/resolv.conf


ASSIGNING IPS TO A CONTAINER:
CREATE A NEW CONTAINER AND ASSIGN AN IP TO IT:

docker container run -d --name network-test02 --ip 10.1.4.102 --network br04 nginx

GET THE IP INFO FOR THE CONTAINER:

docker container inspect network-test02 | grep IPAddr


INSPECT NETWORK-TEST03 TO SEE THAT BR01 WAS REMOVED:

docker container inspect network-test04


Networking two containers


CREATE AN INTERNAL NETWORK:

docker network create -d bridge --internal localhost

CREATE A MYSQL CONTAINER THAT IS CONNECTED TO LOCALHOST:

docker container run -d --name test_mysql \
-e MYSQL_ROOT_PASSWORD=P4sSw0rd0 \
--network localhost mysql:5.7

CREATE A CONTAINER THAT CAN PING THE MYSQL CONTAINER:

docker container run -it --name ping-mysql \
--network bridge \
centos

CONNECT PING-MYSQL TO THE LOCALHOST NETWORK:

docker network connect localhost ping-mysql

RESTART AND ATTACH TO CONTAINER:

docker container start -ia ping-mysql

CREATE A CONTAINER THAT CAN'T PING THE MYSQL CONTAINER:

docker container run -it --name cant-ping-mysql \
centos

CREATE A NGINX CONTAINER THAT IS NOT PUBLICLY ACCESSIBLE:

docker container run -d --name private-nginx -p 8081:80 --network localhost nginx

INSPECT PRIVATE-NGINX:

docker container inspect private-nginx



--------
STORAGE OVERVIEW

we will look a how Docker handles storage for persistent and non-persistent data.


CATEGORIES OF DATA STORAGE:

- Non-persistent
Local storage
Data that is ephemeral
Every container has it
Tied to the lifecycle of the contain

- Persistent
Volumes
Volumes are decoupled from containers


NON-PERSISTENT DATA:

By default all container use local storage

STORAGE LOCATIONS:
Linux: /var/lib/docker/[STORAGE-DRIVER]/
Windows: C:\ProgramData\Docker\windowsfilter\

STORAGE DRIVERS:
RHEL uses overlay2.
Ubuntu uses overlay2 or aufs.
SUSE uses btrfs.
Windows uses its own.



Persistent Data Using Volumes
VOLUMES:

USE A VOLUME FOR PERSISTENT DATA:
Create the volume first, then create your container.
Mounted to a directory in the container
Data is written to the volume
Deleting a container does not delete the volume
First-class citizens
Uses the local driver

THIRD PARTY DRIVERS:
Block storage  - high performance or small block like amzon ECS,
File storage    - high performance on cloud netfs,azure file storage.amzaon EFS
Object storage  - Don't change  often like s3,openstack shift


STORAGE LOCATIONS:
Linux: /var/lib/docker/volumes/
Windows: C:\ProgramData\Docker\volumes



------


VOLUME COMMANDS
Volumes are the preferred method of maintaining persistent data in Docker. In this lesson, we will begin learning how to use the volume subcommand to list, create, and remove volumes.

VOLUME BASICS
LIST ALL DOCKER VOLUME COMMANDS:

docker volume -h
create: Create a volume.
inspect: Display detailed information on one or more volumes.
ls: List volumes.
prune: Remove all unused local volumes.
rm: Remove one or more volumes.


LIST ALL VOLUMES ON A HOST:

#docker volume ls

CREATE TWO NEW VOLUMES:

#docker volume create test-volume1
#docker volume create test-volume2

GET THE FLAGS AVAILABLE WHEN CREATING A VOLUME:

#docker volume create -h

INSPECTING A VOLUME:

#docker volume inspect test-volume1

DELETING A VOLUME:

#docker volume rm test-volume

REMOVING ALL UNUSED VOLUMES:

#docker volume prune



-----

USING BIND MOUNTS
Bind mounts have been around since the early days of Docker. They have limited functionality compared to volumes. With bind mount, a file or directory on the host machine is mounted into a container.

Volumes use a new directory that is created within Docker’s storage directory on the host machine, and Docker manages that directory’s contents.

USING THE MOUNT FLAG:

mkdir target

# docker container run -d \
  --name nginx-bind-mount1 \
  --mount type=bind,source="$(pwd)"/target,target=/app \
  nginx
# docker container ls

BIND MOUNTS WON'T SHOW UP WHEN LISTING VOLUMES:

# docker volume ls


Inspect the container to find the bind mount:

# docker container inspect nginx-bind-mount1


Create a new file in /app on the container:

# docker container exec -it nginx-bind-mount1 /bin/bash
# cd target
# touch file1.txt
# ls
# exit


USING THE VOLUME FLAG:

docker container run -d \
 --name nginx-bind-mount2 \
 -v "$(pwd)"/target2:/app \
 nginx


CREATE /APP/FILE3.TXT IN THE CONTAINER:

docker container exec -it nginx-bind-mount2 touch /app/file3.txt
ls target2


CREATE AN NGINX.CONF FILE:

mkdir nginx
cat << EOF >  nginx/nginx.conf
user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include /etc/nginx/conf.d/*.conf;
}
EOF




CREATE AN NGINX CONTAINER THAT CREATES A BIND MOUNT TO NGINX.CONF:

docker container run -d \
 --name nginx-bind-mount3 \
 -v "$(pwd)"/nginx/nginx.conf:/etc/nginx/nginx.conf \
 nginx


LOOK AT THE BIND MOUNT BY INSPECTING THE CONTAINER:

docker container inspect nginx-bind-mount3





------


USING VOLUMES FOR PERSISTENT STORAGE

we will take a deeper look into using volumes with our Docker containers. Volumes are the preferred method for maintaining persistent data.

Volumes are easier to back up or migrate than bind mounts. You can manage volumes using Docker CLI commands or the Docker API. They work on both Linux and Windows containers. Volumes can be more safely shared among multiple containers. Volume drivers allow for:

  - Storing volumes on remote hosts or cloud providers
  - Encrypting the contents of volumes
  - Add other functionality

New volumes can have their content pre-populated by a container.

CREATE A NEW VOLUME FOR AN NGINX CONTAINER:

# docker volume create html-volume

CREATING A VOLUME USING THAT VOLUME MOUNT:

# docker container run -d \
 --name nginx-volume1 \
 --mount type=volume,source=html-volume,target=/usr/share/nginx/html/ \
 nginx

INSPECT THE VOLUME:

# docker volume inspect html-volume
LIST THE CONTENTS OF HTML-VOLUME:

# sudo ls /var/lib/docker/volumes/html-volume/_data
CREATING A VOLUME USING THAT VOLUME FLAG:

# docker container run -d \
 --name nginx-volume2 \
 -v html-volume:/usr/share/nginx/html/ \
 nginx
EDIT INDEX.HTML:

# sudo vi /var/lib/docker/volumes/html-volume/_data/index.html
INSPECT NGINX-VOLUME2 TO GET THE PRIVATE IP:

# docker container inspect nginx-volume2
LOGIN INTO NGINX-VOLUME1 AND GO TO THE HTML DIRECTORY:

# docker container exec -it nginx-volume1 /bin/bash
# cd /usr/share/nginx/html
# cat index.hml

INSTALL VIM:

# apt-get update -y
# apt-get install vim -y

USING A READONLY VOLUME:

# docker run -d \
  --name=nginx-volume3 \
  --mount source=html-volume,target=/usr/share/nginx/html,readonly \
  nginx

LOGIN INTO NGINX-VOLUME3 AND GO TO THE HTML DIRECTORY:

# docker container exec -it nginx-volume3 /bin/bash
# cd /usr/share/nginx/html
# cat index.hml

INSTALL VIM:

# apt-get update -y
# apt-get install vim -y


-----

INTRODUCTION TO THE DOCKERFILE

we will start learning about building images using a Dockerfile.

WHAT IS THE DOCKERFILE?
Dockerfiles are instructions. They contains all of the commands used to build an image.

Docker images consist of read-only layers.
Each represents a Dockerfile instruction.
Layers are stacked.
Each layer is a result of the changes from the previous layer.
Images are built using the docker image build command.
Dockerfile Layers

DOCKERFILE:  
FROM ubuntu:15.04  
COPY . /app  
RUN make /app  
CMD python /app/app.py

FROM creates a layer from the ubuntu:15.04 Docker image.
COPY adds files from your Docker client’s current directory.
RUN builds your application with make.
CMD specifies what command to run within the container.

Best Practices
GENERAL GUIDELINES:

Keep containers as ephemeral as possible.
Follow Principle 6 of the 12 Factor App.
Avoid including unnecessary files.
Use .dockerignore.
Use multi-stage builds.
Don’t install unnecessary packages.
Decouple applications.
Minimize the number of layers.
Sort multi-line arguments.
Leverage build cache.




------

WORKING WITH INSTRUCTIONS


FROM: Initializes a new build stage and sets the Base Image

RUN: Will execute any commands in a new layer

CMD: Provides a default for an executing container. There can only be one CMD instruction in a Dockerfile

LABEL: Adds metadata to an image

EXPOSE: Informs Docker that the container listens on the specified network ports at runtime

ENV: Sets the environment variable <key> to the value <value>

ADD: Copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the image at the path <dest>.

COPY: Copies new files or directories from <src> and adds them to the filesystem of the container at the path <dest>.

ENTRYPOINT: Allows for configuring a container that will run as an executable

VOLUME: Creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers

USER: Sets the user name (or UID) and optionally the user group (or GID) to use when running the image and for any RUN, CMD, and ENTRYPOINT instructions that follow it in the Dockerfile

WORKDIR: Sets the working directory for any RUN, CMD, ENTRYPOINT, COPY, and ADD instructions that follow it in the Dockerfile

ARG: Defines a variable that users can pass at build-time to the builder with the docker build command, using the --build-arg <varname>=<value> flag

ONBUILD: Adds a trigger instruction to the image that will be executed at a later time, when the image is used as the base for another build

HEALTHCHECK: Tells Docker how to test a container to check that it is still working

SHELL: Allows the default shell used for the shell form of commands to be overridden

TO SET UP THE ENVIRONMENT:

sudo yum install git -y
mkdir docker_images
cd docker_images
mkdir weather-app
cd weather-app
git clone https://github.com/linuxacademy/content-weather-app.git src


CREATE THE DOCKERFILE:

vi Dockerfile
Dockerfile contents:

# Create an image for the weather-app
FROM node
LABEL org.label-schema.version=v1.1
RUN mkdir -p /var/node
ADD src/ /var/node/
WORKDIR /var/node
RUN npm install
EXPOSE 3000
CMD ./bin/www

BUILD THE WEATHER-APP IMAGE:

docker image build -t linuxacademy/weather-app:v1 .     # . or /path of the docker file

LIST THE IMAGES:

docker image ls

CREATE THE WEATHER-APP CONTAINER:

docker container run -d --name weather-app1 -p 8081:3000 linuxacademy/weather-app:v1

LIST ALL RUNNING CONTAINERS:

docker container ls


https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#add-or-copy



----------
 ENVIRONMENT VARIABLES

 To make new software easier to run, you can use ENV to update the PATH environment variable for the software that your container installs.

SETUP YOUR ENVIRONMENT:

cd docker_images
mkdir env
cd env

USE THE --ENV FLAG TO PASS AN ENVIRONMENT VARIABLE WHEN BUILDING AN IMAGE:

--env [KEY]=[VALUE]


USE THE ENV INSTRUCTION IN THE DOCKERFILE:

ENV [KEY]=[VALUE]  
ENV [KEY] [VALUE]


CLONE THE WEATHER-APP:

git clone https://github.com/linuxacademy/content-weather-app.git src
Create the Dockerfile

vi Dockerfile
DOCKERFILE CONTENTS:

# Create an image for the weather-app
FROM node
LABEL org.label-schema.version=v1.1
ENV NODE_ENV="development"
ENV PORT 3000

RUN mkdir -p /var/node
ADD src/ /var/node/
WORKDIR /var/node
RUN npm install
EXPOSE $PORT
CMD ./bin/www



Create the weather-app container:

docker image build -t linuxacademy/weather-app:v2 .

Inspect the container to see the environment variables:

docker image inspect linuxacademy/weather-app:v2

Deploy the weather-dev application:

docker container run -d --name weather-dev -p 8082:3001 --env PORT=3001 linuxacademy/weather-app:v2

Inspect the development container to see the environment variables:

docker container inspect weather-dev


Deploy the weather-app to production:

docker container run -d --name weather-app2 -p 8083:3001 --env PORT=3001 --env NODE_ENV=production linuxacademy/weather-app:v2

Inspect the production container to see the environment variables:

docker container inspect weather-app2

Get the logs for weather-app2:

docker container logs weather-app2
docker container run -d --name weather-prod -p 8084:3000 --env NODE_ENV=production linuxacademy/weather-app:v2





--------

BUILD ARGUMENTS:


we will explore using build arguments to paramerterize an image build.

Use the --build-arg flag when building an image:

--build-arg [NAME]=[VALUE]

Use the ARG instruction in the Dockerfile:

ARG [NAME]=[DEFAULT_VALUE]

Navigate to the args directory:

cd docker_images
mkdir args
cd args

Clone the weather-app:

git clone https://github.com/linuxacademy/content-weather-app.git src


Create the Dockerfile:

vi Dockerfile
Dockerfile:

# Create an image for the weather-app
FROM node
LABEL org.label-schema.version=v1.1
ARG SRC_DIR=/var/node

RUN mkdir -p $SRC_DIR
ADD src/ $SRC_DIR
WORKDIR $SRC_DIR
RUN npm install
EXPOSE 3000
CMD ./bin/www


Create the weather-app container:

docker image build -t linuxacademy/weather-app:v3 --build-arg SRC_DIR=/var/code .

Inspect the image:

docker image inspect linuxacademy/weather-app:v3 | grep WorkingDir

Create the weather-app container:

docker container run -d --name weather-app3 -p 8085:3000 linuxacademy/weather-app:v3

Verify that the container is working by executing curl:

curl localhost:8085



-------WORKING WITH NON-PRIVILEGED USERS

you will learn how to use the USER instruction to create a non-privileged user. Rather than using root, we can use a non-privileged user to configure and run an application.

SETUP YOUR ENVIRONMENT:

cd docker_images
mkdir non-privileged-user
cd non-privileged-user


CREATE THE DOCKERFILE:
vi Dockerfile

DOCKERFILE CONTENTS:

# Creates a CentOS image that uses cloud_user as a non-privileged user
FROM centos:latest
RUN useradd -ms /bin/bash cloud_user
USER cloud_user

BUILD THE NEW IMAGE:

docker image build -t centos7/nonroot:v1 .

CREATE A CONTAINER USING THE NEW IMAGE:

docker container run -it --name test-build centos7/nonroot:v1 /bin/bash

CONNECTING AS A PRIVILEGED USER:

docker container start test-build
docker container exec -u 0 -it test-build /bin/bash

SET UP THE ENVIRONMENT:

cd ~/docker_images
mkdir node-non-privileged-user
cd node-non-privileged-user

CREATE THE DOCKERFILE:

vi Dockerfile

DOCKERFILE CONTENTS:

# Create an image for the weather-app
FROM node
LABEL org.label-schema.version=v1.1
RUN useradd -ms /bin/bash node_user
USER node_user
ADD src/ /home/node_user
WORKDIR /home/node_user
RUN npm install
EXPOSE 3000
CMD ./bin/www
git clone https://github.com/linuxacademy/content-weather-app.git src


BUILD THE WEATHER-APP IMAGE USING THE NON-PRIVILEGED USER NODE_USER:

docker image build -t linuxacademy/weather-app-nonroot:v1 .


CREATE A CONTAINER USING THE LINUXACADEMY/WEATHER-APP-NONROOT:V1 IMAGE:

docker container run -d --name weather-app-nonroot -p 8086:3000 linuxacademy/weather-app-nonroot:v1



--------

ORDER OF EXECUTION

 focuses on the order that instructions are executed in when building an image. Some instructions may have unintended consequences that can cause your build to fail.

SETUP YOUR ENVIRONMENT:

cd docker_images
mkdir centos-conf
cd centos-conf

CREATE THE DOCKERFILE:

vi Dockerfile

DOCKERFILE CONTENTS:

# Creates a CentOS image that uses cloud_user as a non-privileged user
FROM centos:latest
RUN mkdir -p ~/new-dir1
RUN useradd -ms /bin/bash cloud_user
USER cloud_user
RUN mkdir -p ~/new-dir2
RUN mkdir -p /etc/myconf
RUN echo "Some config data" >> /etc/myconf/my.conf

BUILD THE NEW IMAGE:

docker image build -t centos7/myconf:v1 .




--------

USING THE VOLUME INSTRUCTION

 we will use the VOLUME instruction to automatically create a mount point in a Docker image. When a container is created using this image, a volume will be created and mounted to the specified directory.

SET UP YOUR ENVIRONMENT:

cd docker_images
mkdir volumes
cd volumes

CREATE THE DOCKERFILE:

vi Dockerfile

BUILD AN NGINX IMAGE THAT USES A VOLUME:

FROM nginx:latest
VOLUME ["/usr/share/nginx/html/"]

BUILD THE NEW IMAGE:

docker image build -t linuxacademy/nginx:v1 .

CREATE A NEW CONTAINER USING THE LINUXACADEMY/NGINX:V1 IMAGE:

docker container run -d --name nginx-volume linuxacademy/nginx:v1

INSPECT NGINX-VOLUME:

docker container inspect nginx-volume

LIST THE VOLUMES:

docker volume ls | grep [VOLUME_NAME]

INSPECT THE VOLUMES:

docker volume inspect [VOLUME_NAME]




-------

ENTRYPOINT VS. COMMAND

 we will begin working with the ENTRYPOINT instruction. Though ENTRYPOINT functions very similarly to CMD it's behaviors are vary different.

ENTRYPOINT allows us to configure a container that will run as an executable.
We can override all elements specified using CMD.
Using the docker run --entrypoint flag will override the ENTRYPOINT instruction.

SETUP YOUR ENVIRONMENT:

cd docker_images
mkdir entrypoint
cd entrypoint

CREATE THE DOCKERFILE:

vi Dockerfile

DOCKERFILE CONTENTS:

# Create an image for the weather-app
FROM node
LABEL org.label-schema.version=v1.1
ENV NODE_ENV="production"
ENV PORT 3001

RUN mkdir -p /var/node
ADD src/ /var/node/
WORKDIR /var/node
RUN npm install
EXPOSE $PORT
ENTRYPOINT ./bin/www

CLONE THE IMAGE:

git clone https://github.com/linuxacademy/content-weather-app.git src

BUILD THE IMAGE:

docker image build -t linuxacademy/weather-app:v4 .

DEPLOY THE WEATHER-APP:

docker container run -d --name weather-app4 linuxacademy/weather-app:v4

INSPECT WEATHER-APP4:

docker container inspect weather-app4 | grep Cmd
docker container inspect weather-app-nonroot
docker container inspect weather-app4

CREATE THE WEATHER-APP CONTAINER:

docker container run -d --name weather-app5 -p 8083:3001 linuxacademy/weather-app:v4 echo "Hello World"

INSPECT WEATHER-APP5:

docker container inspect weather-app5

CREATE THE VOLUMES FOR PROMETHEUS:

docker volume create prometheus
docker volume create prometheus_data

sudo chown -R nfsnobody:nfsnobody /var/lib/docker/volumes/prometheus/
sudo chown -R nfsnobody:nfsnobody /var/lib/docker/volumes/prometheus_data/

CREATE THE PROMETHEUS CONTAINER:

docker run --name prometheus -d -p 8084:9090 \
  -v prometheus:/etc/prometheus \
  -v prometheus_data:/prometheus/data \
  prom/prometheus \
  --config.file=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path=/prometheus/data

INSPECT PROMETHEUS:

docker container inspect prometheus


https://github.com/prometheus/prometheus/blob/master/Dockerfile





--------

BUILDING IMAGES

We will learn some alternate ways of building images.

TO BUILD ONE:

docker image build -t <NAME>:<TAG> .

USEFUL FLAGS:

-f, --file string: This is the name of the Dockerfile (Default is PATH/Dockerfile).
--force-rm: Always remove intermediate containers.
--label list: Set metadata for an image.
--rm: Remove intermediate containers after a successful build (default is true).
--ulimit ulimit: This sets ulimit options (default is []).
cd docker_images/weather-app
cp Dockerfile Dockerfile.test
docker image build -t linuxacademy/weather-app:path-example1 -f Dockerfile.test .
docker image build -t linuxacademy/weather-app:path-example2 --label com.linuxacademy.version=v1.8 -f Dockerfile.test .


BUILDING IMAGE BY PIPING THE DOCKERFILE THROUGH STDIN:

docker image build -t <NAME>:<TAG> -<<EOF
Build instructions
EOF

EXAMPLE:

docker image build -t linuxacademy/nginx:stind --rm -<<EOF
FROM nginx:latest
VOLUME ["/usr/share/nginx/html/"]
EOF

BUILDING AN IMAGE USING A URL:

docker image build -t <NAME>:<TAG> <GIT_URL>#<REF>
docker image build -t <NAME>:<TAG> <GIT_URL>#:<DIRECTORY>
docker image build -t <NAME>:<TAG> <GIT_URL>#<REF>:<DIRECTORY>

EXAMPLE:

docker image build -t linuxacademy/weather-app:github https://github.com/linuxacademy/content-weather-app.git#remote-build

BUILDING AN IMAGE FROM A ZIP FILE:

docker image build -t <NAME>:<TAG> - < <FILE>.tar.gz

EXAMPLE:

cd docker_images
mkdir tar_image
cd tar_image
git clone https://github.com/linuxacademy/content-weather-app.git
cd content-weather-app
git checkout remote-build
tar -zcvf weather-app.tar.gz Dockerfile src
docker image build -t linuxacademy/weather-app:from-tar - < weather-app.tar.gz


------

USING MULTI-STAGE BUILDS

we will learn how to build smaller images using multi-stage builds.

By default, the stages are not named
Stages are numbered with integers
Starting with 0 for the first FROM instruction
Name the stage by adding as to the FROM instruction
Reference the stage name in the COPY instruction

SET UP YOUR ENVIRONMENT:

cd docker_images
mkdir multi-stage-builds
cd multi-stage-builds
git clone https://github.com/linuxacademy/content-weather-app.git src

CREATE THE DOCKERFILE:

vi Dockerfile

DOCKERFILE CONTENTS:

# Create an image for the weather-app using multi-stage build
FROM node AS build
RUN mkdir -p /var/node/
ADD src/ /var/node/
WORKDIR /var/node
RUN npm install

FROM node:alpine
ARG VERSION=V1.1
LABEL org.label-schema.version=$VERSION
ENV NODE_ENV="production"
COPY --from=build /var/node /var/node
WORKDIR /var/node
EXPOSE 3000
ENTRYPOINT ["./bin/www"]

BUILD THE IMAGE:

docker image build -t linuxacademy/weather-app:multi-stage-build --rm --build-arg VERSION=1.5 .

LIST IMAGES TO SEE THE SIZE DIFFERENCE:

docker image ls

CREATE THE WEATHER-APP CONTAINER:

docker container run -d --name multi-stage-build -p 8087:3000 linuxacademy/weather-app:multi-stage-build  





-------

TAGGING:
    
we will talk about how to use the tag command, and best practices to keep in mind when tagging.



ADD A NAME AND AN OPTIONAL TAG WITH -T OR --TAG, IN THE NAME:TAG FORMAT:

docker image build -t <name>:<tag>
docker image build --tag <name>:<tag>

LIST YOUR IMAGES:

docker image ls

USE OUR GIT COMMIT HASH AS THE IMAGE TAG:

git log -1 --pretty=%H

USE THE DOCKER TAG TO A CREATE A NEW TAGGED IMAGE:


docker tag <SOURCE_IMAGE><:TAG> <TARGET_IMAGE>:<TAG>

GET THE COMMIT HASH:

cd docker_images/weather-app/src
git log -1 --pretty=%H
cd ../

BUILD THE IMAGE USING THE GIT HASH AS THE TAG:


docker image build -t linuxacademy/weather-app:<GIT_HASH> .

TAG THE WEATHER-APP AS THE LATEST USING THE IMAGE TAGGED WITH THE COMMIT HASH:


docker image tag linuxacademy/weather-app:<GIT_HASH> linuxacademy/weather-app:latest





-------


DISTRIBUTING IMAGES ON DOCKER HUB

We'll walk through how to tag and push an image to Docker Hub. You will need a Docker Hub account.

Create a Docker Hub account:

https://hub.docker.com/

Docker Push:
docker image push <USERNAME>/<IMAGE_NAME>:<TAG>

Creating an image for Docker Hub:
docker image tag <IMAGE_NAME>:<TAG> <linuxacademy>/<IMAGE_NAME>:<TAG>

Set up your environment:

cd docker_images
mkdir dockerhub
cd dockerhub

Create the Dockerfile:

vi Dockerfile

Dockerfile contents:

# Create an image for the weather-app using multi-stage build
FROM node AS build
RUN mkdir -p /var/node/
ADD src/ /var/node/
WORKDIR /var/node
RUN npm install

FROM node:alpine
ARG VERSION=V1.1
LABEL org.label-schema.version=$VERSION
ENV NODE_ENV="production"
COPY --from=build /var/node /var/node
WORKDIR /var/node
EXPOSE 3000
ENTRYPOINT ["./bin/www"]

Git the weather-app code:

git clone https://github.com/linuxacademy/content-weather-app.git src

Use the Git commit hash as the image tag:

cd src
git log -1 --pretty=%H
cd ../

Build the image:

docker image build -t <USERNAME>/weather-app:<HASH> --build-arg VERSION=1.5 .

Tag the image before pushing it to Docker Hub:

docker image tag linuxacademy/weather-app:<HASH> <USERNAME>/weather-app:<HASH>

Push the image to Docker Hub:

docker login 
docker image push <USERNAME>/weather-app:<HASH>

Tag the latest image:
docker image tag <USERNAME>/weather-app:<HASH> <USERNAME>/weather-app:latest

Push the latest image to Docker Hub:
 docker login <USERNAME>
docker image push <USERNAME>/weather-app:latest





=======

Managing Images

Image History
We see how to get more information about an image by looking at its history.

Show the history of an image:

docker image history <IMAGE>
docker image history --no-trunc <IMAGE>
docker image history --quiet <IMAGE>
docker image history --quiet --no-trunc <IMAGE>

Get the image history for Node:

docker image history node:latest

Get the image history for weather-app:

docker image history rivethead42/weather-app:latest

Get the image history weather-app:v1 with the no-truncm flag:

docker image history --no-trunc linuxacademy/weather-app:v1

Save the output using the no-truncm flag to a file:

docker image history --no-trunc linuxacademy/weather-app:v1 > output.txt

View the contents:

vi output.txt

Use the quiet flag to list the image IDs:

docker image history --quiet linuxacademy/weather-app:v1

Use the quiet flag to list the image IDs, then save the output to a file using the no-truncm flag:

docker image history --quiet --no-trunc linuxacademy/weather-app:v1





------


SAVING AND LOADING IMAGES

we will learn how to save an image to a tar file, and see how to load it back in.

Save one or more images to a tar file:

docker image save <IMAGE> > <FILE>.tar
docker image save <IMAGE> -o <FILE>.tar
docker image save <IMAGE> --output <FILE>.tar

Load an image from a tar file:

docker image load < <FILE>.tar
docker image load -i <FILE>.tar
docker image load --input <FILE>.tar

Setup:

mkdir output
cd output

Archive the rivethead42/weather-app:latest image:

docker image save rivethead42/weather-app:latest --output weather-app-latest.tar

Inspect the tar file:

tar tvf weather-app-latest.tar

Compress the tar file:

gzip weather-app-latest.tar

Delete the image:

docker image rm [USERNAME]/weather-app:latest

Load the weather-app image from a tar file:

docker image load --input weather-app-latest.tar.gz
docker image ls | grep [USERNAME]/weather-app
docker image rm rivethead42/weather-app:latest docker image ls | grep rivethead42/weather-app






=======

-------

BEYOND THE DOCKER BASICS

INSPECTING CONTAINER PROCESSES

 we'll take a look at a few ways we can examine the running processes in a container.

DOCKER TOP:

docker container top <NAME>
DOCKER STATS:

docker container stats <NAME>
CREATE A NEW CENTOS CONTAINER:

docker container run -itd --name container_process centos /bin/bash

EXECUTE DOCKER CONTAINER TOP:

docker container top container_process

===

ATTACH TO CONTAINER_PROCESS:

--->> exec & attach - can be used to connect containers, but attach will stop running, once you exit from the container


docker container exec -it container_process /bin/bash  - 

ATTACH TO THE CONTAINER USING ATTACH:

docker container attach container_process - ## once you exit from the container it will stop the container




RESTART THE CONTAINER:

docker container start container_process
ATTACH TO THE CONTAINER_PROCESS CONTAINER:

docker container exec -it container_process /bin/bash
RUN TOP ON THE CONTAINER:

top
exit

GET STATS ON A CONTAINER:

docker container stats container_process   - to check this, go to another terminal then  run yum update




-----


HAVING CONTAINERS START AUTOMATICALLY

We will look at how to set restart policies for containers, and how that will effect their behavior when the docker service is restarted.

TO CONFIGURE THE RESTART POLICY FOR A CONTAINER, USE THE --RESTART FLAG:

no: Do not automatically restart the container. (the default)
on-failure: Restart the container if it exits due to an error, which manifests as a non-zero exit code.
always: Always restart the container if it stops.
unless-stopped: Similar to always, except that when the container is stopped, it is not restarted even after the Docker daemon restarts.


AUTOMATICALLY RESTARTING A CONTAINER:

docker container run -d --name <NAME> --restart <RESTART> <IMAGE>

MAKE SURE A CONTAINER ALWAYS RESTARTS:
docker container run -d --name always-restart --restart always rivethead42/weather-app:latest

MAKE SURE A CONTAINER RESTARTS UNLESS IT'S STOPPED:
docker container run -d --name unless-stopped --restart unless-stopped rivethead42/weather-app:latest

STOP AND RESTART YOUR DOCKER SERVICE:
sudo systemctl restart docker

LIST YOUR CONTAINERS:
docker container ls

STOP THE UNLESS-STOPPED CONTAINER:
docker container stop unless-stopped

STOP AND RESTART YOUR DOCKER SERVICE:
sudo systemctl restart docker

LIST YOUR CONTAINERS:
docker container ls

STOP THE UNLESS-STOPPED CONTAINER:
docker container stop always-restart

STOP AND RESTART YOUR DOCKER SERVICE:
sudo systemctl restart docker

LIST YOUR CONTAINERS:
docker container ls




------


DOCKER EVENTS

We'll see how to listen for events using the events command.

Get real-time events from the server:

docker system events
docker system events --since '<TIME_PERIOD>'

Start a new CentOS container:
docker container run -itd --name docker_events centos /bin/bash

Listen for events:
docker system events

Generate Events:

docker container exec docker_events /bin/bash
docker container attach docker_events
docker container start docker_events

Filters Events:
docker system events --filter <FILTER_NAME>=<FILTER>

Filter for container events:
docker system events --filter type=container --since '1h'

Generate an event:
docker container exec docker_events ls /

Filter for container events:
docker system events --filter type=container --filter event=start --since '1h'

List / on docker_events:
docker container exec docker_events ls /

Filter for attach events:
docker system events --filter type=container --filter event=attach

Connect to docker_events using /bin/bash:
docker container exec -it docker_events /bin/bash

Attach to docker_events:
docker container attach docker_events

Connect to docker_events using /bin/bash:
docker container exec -it docker_events /bin/bash

Attach to docker_events:
docker container attach docker_events

Use multiple filters:
docker system events --filter type=container --filter event=attach --filter event=die --filter event=stop

Start docker_events:
docker container start docker_events

Attach to docker_events:
docker container attach docker_events

Documentation:

docker events -- https://docs.docker.com/engine/reference/commandline/events/

Engine API v1.24 - https://docs.docker.com/engine/api/v1.24/




-----

MANAGING STOPPED CONTAINER

We will manage stopped containers by starting, deleting, or pruning them.

Remove one or more containers:

docker container rm <NAME>

List the rm flags:
docker container rm -h

Start one or more stopped containers:
docker container start <NAME>

Remove all stopped containers:
docker container prune

List the IDs of all containers:
docker container ls -a -q

List all stopped containers:
docker container ls -a -f status=exited

List the IDs of stopped containers:
docker container ls -a -q -f status=exited

Get a count of all stopped containers:
docker container ls -a -q -f status=exited | wc -l

Get a listing of our containers:
docker container ls -a -f status=exited | grep prometheus

Start Prometheus:
docker container start prometheus

Fin stopped weather-app containers with grep:
docker container ls -a -f status=exited | grep weather-app

Remove stopped weather-app containers:
docker container rm [CONTAINER_IDS]

Prune all stopped containers:
docker container prune





------

MANAGING DOCKER WITH PORTAINER

We'll install Portainer and use it manage our Docker host.

Create a volume for Portainers data:

docker volume create portainer_data

Create the Portainers container:

docker container run -d --name portainer -p 8080:9000 \
--restart=always \
-v /var/run/docker.sock:/var/run/docker.sock \
-v portainer_data:/data portainer/portainer


docker container ls

The ls should output:

vijaythilak/weather-app:latest
NODE_ENV production




------

UPDATING CONTAINERS WITH WATCHTOWER:


We'll see how to use Watchtower to keep a container up-to-date when its image gets updated.

Clone Express app:

git clone https://github.com/linuxacademy/content-express-demo-app.git watchtower
cd watchtower
git checkout dockerfile

Build the Docker image:

docker login -u [USERNAME]
docker image build -t rivethead42/my-express .
docker image push rivethead42/my-express

Create the container:

docker container run -d --name watched-app -p 80:3000 --restart always rivethead42/my-express

Create Watchtower:

docker container run -d --name watchtower \
--restart always \
-v /var/run/docker.sock:/var/run/docker.sock \
v2tec/watchtower -i 15


Add a .dockerignore file:

vi .dockerignore

.dockerignore contents:

Dockerfile
.git
.gitignore

Edit app.js and add a comment:

vi app.js
app.js contents:

//This is a comment
//
...

Add the file newfile.js:

touch newfile.js

Rebuild the image:

docker image build -t rivethead42/my-express --no-cache .
docker image push rivethead42/my-express

Check to see if the container was restarted with the new image:

docker container ls

Verify the changes by attaching to watched-app:

docker container exec -it watched-app /bin/bash



------

INSTALLING DOCKER COMPOSE:

We will learn about installing Docker Compose and why we should use it.

 --> when we deploy more & more micro services, its difficult to manage

Download the latest version of Docker Compose:

sudo curl -L "https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

Apply executable permissions:

sudo chmod +x /usr/local/bin/docker-compose

Test Docker Compose:

docker-compose --version




-----

COMPOSE COMMANDS


We will start using compose by creating a compose file. Then we will create and manage the services by using the most commonly used commands:

build: Build or rebuild services
bundle: Generate a Docker bundle from the Compose file
config: Validate and view the Compose file
create: Create services
down: Stop and remove containers, networks, images, and volumes
events: Receive real time events from containers
exec: Execute a command in a running container
help: Get help on a command
images: List images
kill: Kill containers
logs: View output from containers
pause: Pause services
port: Print the public port for a port binding
ps: List containers
pull: Pull service images
push: Push service images
restart: Restart services
rm: Remove stopped containers
run: Run a one-off command
scale: Set number of containers for a service
start: Start services
stop: Stop services
top: Display the running processes
unpause: Unpause services
up: Create and start containers
version: Show the Docker-Compose version information

Setup your environment:

mkdir -p compose/commands
cd compose/commands

Create a docker-compose file:
vi docker-compose.yml

docker-compose.yml contents:

version: '3'
services:
  web:
    image: nginx
    ports:
    - "8080:80"
    volumes:
    - nginx_html:/usr/share/nginx/html/
    links:
    - redis
  redis:
    image: redis
volumes:
  nginx_html: {}


Create a compose service:
docker-compose up -d

List containers created by compose:
docker-compose ps

Stopping a compose service:
docker-compose stop

Starting a compose service:
docker-compose start

Restarting a compose service:
docker-compose restart

Delete a compose service:
docker-compose down



------

CREATING A COMPOSE FILE:



 we will look at the basics of creating a compose file.

Setup your environment:

cd compose
git clone https://github.com/linuxacademy/content-weather-app.git weather-app
cd weather-app
git checkout compose


Create a docker-compose.yml file:
vi docker-compose.yml

docker-compose.yml contents:

version: '3'
services:
  weather-app:
    build:
      context: .
      args:
        - VERSION=v2.0
    ports:
      - "8081:3000"
    environment:
      - NODE_ENV=production




root@vijaythilak2c weather-app]# docker-compose ps
          Name                         Command                State     Ports
-----------------------------------------------------------------------------
weather-app_weather-app_1   docker-entrypoint.sh /bin/ ...   Exit 143  



TO RENAME A CONTAINER, UNDER -->  weather-app: 
                               container_name: anyname


root@vijaythilak2c weather-app]# docker-compose ps
    Name                  Command               State           Ports         
------------------------------------------------------------------------------
weather_app1   docker-entrypoint.sh /bin/ ...   Up      0.0.0.0:8081->3000/tcp




Create the compose container:
docker-compose up -d

List compose services:
docker-compose ps

Verify the weather-app is working:
curl http://localhost:8081

Rebuild the image:
docker-compose build

Rebuild the image with no cache:
docker-compose build --no-cache




------

USING VOLUMES AND NETWORKING WITH COMPOSE

We will learn how to use volumes and networks in a docker compose file.

Setup your environment:

mkdir -p compose/ghost
cd compose/ghost

Create a docker-compose.yml file:
vi docker-compose.yml

docker-compose.yml:

version: '3'
services:
  ghost:
    container_name: ghost
    image: ghost:latest
    ports:
      - "80:2368"
    environment:
      - database__client=mysql
      - database__connection__host=mysql
      - database__connection__user=root
      - database__connection__password=P4SSw0rd0!
      - database__connection__database=ghost
    volumes:
      - ghost-volume:/var/lib/ghost
    networks:
      - ghost_network
      - mysql_network
    depends_on:
      - mysql

  mysql:
    container_name: mysql
    image: mysql:5.7
    environment:
      - MYSQL_ROOT_PASSWORD=P4SSw0rd0!
    volumes:
      - mysql-volume:/var/lib/mysql
    networks:
      - mysql_network

volumes:
  ghost-volume:
  mysql-volume:

networks:
  ghost_network:
  mysql_network:



Create the compose container:
docker-compose up -d

List compose services:
docker-compose ps

List the volumes:
docker volumes ls

List the volumes:
docker network ls

https://docs.docker.com/compose/compose-file/




-------

INTRODUCTION TO DOCKER SWARM

We'll look at the highlights of Docker Swarm before we start working with it.


SWARM HAS TWO MAJOR COMPONENTS:

An enterprise grade secure cluster:

Manage one or more Docker nodes as a cluster
Encrypted distributed cluster store
Encrypted networks
Secure join tokens

An orchestration engine for creating mircoservices:

API for deploying and managing microservices
Declarative manifest files for defining apps
Provides availability to scale apps, and perform rolling updates and rollbacks
Swarm was initially a separate product layered on Docker, since Docker 1.12 it has become a part of the engine.

The Cluster
A swarm consists of one or more Docker nodes.
Nodes are either a managers or a worker.

Managers:
Manage the state of the cluster
Dispatch tasks to workers

Workers:
Accepts and execute tasks
State is held in etcd
Swarm uses Transport Layer Security (TLS):
Encrypted communication
Authenticated nodes
Authorized roles
Orchestration
The atomic unit of scheduling is a swarm service.

The service construct adds the following to a container:
scaling
rolling updates
rollback
updates
A container wrapped in a service is a task or a replica.



------

RUNNING DOCKER IN SWARM MODE

We will create two new docker servers. These servers will be used in a swarm configuration. Then we will initialize the swarm manager and have the two new nodes join the swarm.

Install the Swarm Worker Node
Now create two new servers in Cloud Playground that will be used as worker nodes.

Prerequisites
Uninstall old versions:

sudo yum remove -y docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine


Install Docker CE
Add the Docker repository:

sudo yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2

Set up the stable repository:

sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo


Install Docker CE:
sudo yum -y install docker-ce

Enable and Start Docker:
sudo systemctl start docker && sudo systemctl enable docker

Add cloud_user to the docker group:
sudo usermod -aG docker cloud_user

Initialize the manager:
docker swarm init \
--advertise-addr [PRIVATE_IP]


Add the worker to the cluster:
docker swarm join --token [TOKEN] \
[PRIVATE_IP]:2377

List the nodes in the swarm:
docker node ls




------


MANAGING SWARM NODES:

We learn how to manage the nodes in the swarm.

Docker node commands:
demote:-> Demotes one or more nodes from manager in the swarm
inspect:-> Displays detailed information on one or more nodes
ls:-> Lists nodes in the swarm
promote:-> Promotes one or more nodes to manager in the swarm
ps:-> Lists tasks running on one or more nodes, defaults to current node
rm:-> Removes one or more nodes from the swarm
update:-> Updates a node


Docker swarm commands:
ca:-> Displays and rotate the root CA
init:-> Initializes a swarm
join:-> Joins a swarm as a node and/or manager
join-token:-> Manages join tokens
leave:-> Leaves the swarm
unlock:-> Unlocks swarm
unlock-key:-> Manages the unlock key
update:-> Updates the swarm



Managing swarm nodes:
Listing nodes:
docker node ls

Inspecting a node:
docker node inspect [NODE_NAME]

Promoting a worker to a manager:
docker node promote [NODE_NAME]

Demoting a manager to a worker:
docker node demote [NODE_NAME]

Removing a node form the swarm (node must be demoted first):
docker node rm -f [NODE_NAME]

Make a node leave the swarm:
docker swarm leave

Getting the join-token:
docker swarm join-token [worker|manager]

Make the node rejoin the swarm:
docker swarm join --token [TOKEN] \
<PRIVATE_IP>:2377





-------

WORKING WITH SERVICES

We'll see how to create and manage a service running in Docker Swarm.

Docker service commands:

create:-> Creates a new service
inspect:-> Displays detailed information on one or more services
logs:-> Fetches the logs of a service or task
ls:-> Lists services
ps:-> Lists the tasks of one or more services
rm:-> Removes one or more services
rollback:-> Reverts changes to a service's configuration
scale:-> Scales one or multiple replicated services
update:-> Updates a service



Creating a service:
docker service create -d --name [NAME] \
-p [HOST_PORT]:[CONTAINER_PORT] \
--replicas [REPLICAS] \
[IMAGE] [CMD]

List services:
docker service ls

Inspecting a service:
docker service inspect [NAME]

Get logs for a service:
docker service logs [NAME]

List all tasks of a service:
docker service ps [NAME]

Scale a service up or down:
docker service scale [NAME]=[REPLICAS]

Update a service:
docker service update [OPTIONS] [NAME]

Create nginx_service:
docker service create -d --name nginx_service -p 8080:80 --replicas 2 nginx:latest

List the swarm services:
docker service ls

Inspect nginx_service:
docker service inspect nginx_service

Find the network:
docker network ls --no-trunc | grep [NETOWRK_ID]

View the running tasks for nginx_service:
docker service ps nginx_service

Scale nginx_service to 3 replicas:
docker service scale nginx_service=3





-----------


USING NETWORKS IN SWARM MODE

We'll look more into overlay networks and how they are used with a swarm.

Create a overlay network:
docker network create -d overlay [NAME]


Creating a service with an overlay network:
docker service create -d --name [NAME] \
--network [NETWORK] \
-p [HOST_PORT]:[CONTAINER_PORT] \
--replicas [REPLICAS] \
[IMAGE] [CMD]

Add a service to a network:
docker service update --network-add [NETWORK] [SERVICE]

Remove a service from a network:
docker service update --network-rm [NETWORK] [SERVICE]

Create a overlay network:
docker network create -d overlay my_overlay

Create an encrypted overlay network:
docker network create -d overlay --opt encrypted encrypted_overlay

Inspect encrypted_overlay:
docker network inspect encrypted_overlay

Inspect my_overlay:
docker network inspect my_overlay

Create a service using my_overlay:
docker service create -d --name nginx_overlay  --network my_overlay -p 8081:80 --replicas 2 nginx:latest

Adding the my_overlay network to nginx_service:
docker service update --network-add my_overlay nginx_service

Inspect nginx_service:
docker service inspect nginx_service

Removing the ingress network from nginx_service:
docker service update --network-rm my_overlay nginx_service

Inspect nginx_service:
docker service inspect nginx_service

Remove encrypted_overlay:
docker network rm encrypted_overlay




------


USING VOLUMES IN SWARM MODE

We will start learning about plugins, and using volumes in swarm mode. The local driver only creates a volume on the node that a command is executed on. This requires using a third party driver that is specific to the environment.

Add Plugins:

docker plugin install [PLUGIN] [OPTIONS]

List plugins:
docker plugin ls

Volume Plugins:
Hedvig
Pure Storage
HPE Nimble Storage
Nutanix DVP
Blockbridge
NexentaStor
StorageOS
Rex-Ray

Install the Splunk plugin:

docker plugin install store/splunk/docker-logging-plugin:2.0.0 --alias splunk-logging-plugin

Disable a plugin:
docker plugin disable [ID]

Remove a plugin:
docker plugin rm [ID]

Digital Ocean example:
docker plugin install rexray/dobs \
DOBS_REGION=<DO_REGION> \
DOBS_TOKEN=<DIGITAL_OCEAN_TOKEN> \
DOBS_CONVERTUNDERSCORES=true

Create a volume using a driver:
docker volume create -d [DRIVER] [NAME]
docker service create -d --name [NAME] \
--mount type=[TYPE],src=[SOURCE],dst=[DESTINATION] \
-p [HOST_PORT]:[CONTAINER_PORT] \
--replicas [REPLICAS] \
[IMAGE] [CMD]

Create a volume on the manager:
docker volume create -d local portainer_data

Create a portainers service that uses a volume:
docker service create \
--name portainer \
--publish 8000:9000 \
--constraint 'node.role == manager' \
--mount type=volume,src=portainer_data,dst=/data \
--mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \
portainer/portainer \
-H unix:///var/run/docker.sock


https://rexray.readthedocs.io/en/stable/user-guide/schedulers/docker/plug-ins/




-------


DEPLOYING STACKS IN DOCKER SWARM

We will learn how to deploy stacks to Docker Swarm using Docker Compose.

Docker stack commands:
deploy: Deploys a new stack or update an existing stack
ls: Lists stacks
ps: Lists the tasks in the stack
rm: Removes one or more stacks
services: Lists the services in the stack

Setup environment:
mkdir -p swarm/prometheus
cd swarm/prometheus

Create the prometheus.yml file:
vi prometheus.yml

prometheus.yml contents:

global:
  scrape_interval: 15s
  scrape_timeout: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: prometheus
    scrape_interval: 5s
    static_configs:
    - targets:
      - prometheus_main:9090

  - job_name: nodes
    scrape_interval: 5s
    static_configs:
    - targets:
      - [MANAGER]:9100
      - [WORKER1]:9100
      - [WORKER2]:9100

  - job_name: cadvisor
    scrape_interval: 5s
    static_configs:
    - targets:
      - [MANAGER]:8081
      - [WORKER1]:8081
      - [WORKER2]:8081



Create a compose file:
vi docker-compose.yml

docker-compose.yml contents:

version: '3'
services:
  main:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - 8080:9090
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus/data
    volumes:
    - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    - data:/prometheus/data
    depends_on:
      - cadvisor
      - node-exporter
  cadvisor:
    image: google/cadvisor:latest
    container_name: cadvisor
    deploy:
      mode: global
    restart: unless-stopped
    ports:
      - 8081:8080
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    deploy:
      mode: global
    restart: unless-stopped
    ports:
      - 9100:9100
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - --collector.filesystem.ignored-mount-points
      - "^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)"
  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - 8082:3000
    volumes:
    - grafana_data:/var/lib/grafana
    - grafana_plugins:/var/lib/grafana/plugins
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=P4ssW0rd0!
    depends_on:
      - prometheus
      - cadvisor
      - node-exporter

volumes:
  data:
  grafana_data:
  grafana_plugins:

Deploy the stack:

docker stack deploy --compose-file docker-compose.yml prometheus

List stacks:
docker stack ls

List services:
docker service ls

Fix volume permissions:
sudo chown nfsnobody:nfsnobody -R /var/lib/docker/volumes/prometheus_data




-------

INTRODUCTION TO DOCKER SECURITY

We'll begin exploring ways to secure Docker by using security features native to both the operating system and Docker itself.

Docker Security 101
Security is all about layers

Linux security:

Namespaces
Control Groups
Mandatory Access Control (MAC)
Seccomp

Docker security:

Docker Swarm
Docker Content Trust
Docker Security Scanner
Docker secrets
Namespaces
Docker creates a set of namespaces and control groups for the container. Docker containers are an organized collections of namespaces.

Namespaces provide isolation.
Each container also gets its own network stack.

Docker on Linux namespaces:

Process ID (pid)
network (net)
Filesystem/mount (mount)
Inter-process Communication (ipc)
User (user)
UTS (uts)
Control Groups

Control Groups are about setting limits for:

CPU
RAM
Disk I/O
They help to mitigate denial-of-service attacks, and are important on multi-tenant platforms.

Capabilities
Capabilities turn the binary “root/non-root” dichotomy into a fine-grained access control system. In most cases, containers do not need “real” root privileges at all. This means root within a container has much less privileges than the real root. It also means that even if an intruder manages to escalate to root within a container, it is much harder to do serious damage, or to escalate to the host.

Mandatory Access Control systems

Two major MAC technologies are:

SELinux
AppArmor
Seccomp
This limits the syscalls a container can make to the host's kernel. All new containers get a default seccomp configured

Docker Swarm

Swarm Mode:

Cryptographic node Ids
Mutual authentication via TLS
Secure join tokens
CA configuration with automatic certificate rotation
Encrypted cluster store
Encrypted networks
docker swarm update --cert-expiry [INT]h
Docker Secrets

These store sensitive data like:

Passwords
TLS Certificates
API Keys

Secrets Workflow:

A secret is created and posted to the Swarm.
The secret is encrypted and stored.
A service is created and the secret is attached.
Secrets are stored in-flight.
The secret is mounted into the container of a service.
When the task is complete, the in-memory is torn down.  




--------

WORKING WITH DOCKER SECURITY

We will start implementing some of the Docker security practices.

Seccomp Profile
docker container run --security-opt seccomp=[PROFILE] [IMAGE] [CMD]

Testing Seccomp:

docker container run --rm -it alpine sh
whoami
mount /dev/sda1 /tmp
swapoff -a

Using a custom Seccomp profile:

mkdir -p seccomp/profiles/chmod
cd seccomp/profiles/chmod
wget https://raw.githubusercontent.com/moby/moby/master/profiles/seccomp/default.json
Remove chmod, fchmod and fchmodat from the syscalls whitelist. Syscalls starts at line 52.


Applying the custom Seccomp profile:

docker container run --rm -it --security-opt seccomp=./default.json alpine sh
chmod +r /usr
Capabilities:

Dropping Capabilities:

docker container run --cap-drop=[CAPABILITY] [IMAGE] [CMD]

Test mknod:

docker container run --rm -it alpine sh
mknod /dev/random2 c 1 8

Disable mknod:

docker container run --rm -it --cap-drop=MKNOD alpine sh
mknod /dev/random2 c 1 8
Runtime privilege and Linux capabilities

Control Groups

Limiting CPU and memory:

docker container run -it --cpus=[VALUE] --memory=[VALUE][SIZE] --memory-swap [VALUE][SIZE] [IMAGE] [CMD]
Setting memory limits on a container:

docker container run -d --name resource-limits --cpus=".5" --memory=512M --memory-swap=1G rivethead42/weather-app

Inspect resource-limits:

docker container inspect resource-limits
Runtime constraints on resources More info on resource constraints

https://docs.docker.com/config/containers/resource_constraints/
https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources

Running Docker Bench for Security

Running Docker Bench Security:

docker container run --rm -it --network host --pid host --userns host --cap-add audit_control \
    -e DOCKER_CONTENT_TRUST=$DOCKER_CONTENT_TRUST \
    -v /var/lib:/var/lib \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v /usr/lib/systemd:/usr/lib/systemd \
    -v /etc:/etc --label docker_bench_security \
    docker/docker-bench-security


https://github.com/docker/docker-bench-security





------

WORKING WITH DOCKER SECURITY


We will start implementing some of the Docker security practices.

Seccomp Profile
docker container run --security-opt seccomp=[PROFILE] [IMAGE] [CMD]


Testing Seccomp:

docker container run --rm -it alpine sh
whoami
mount /dev/sda1 /tmp
swapoff -a

Using a custom Seccomp profile:

mkdir -p seccomp/profiles/chmod
cd seccomp/profiles/chmod
wget https://raw.githubusercontent.com/moby/moby/master/profiles/seccomp/default.json
Remove chmod, fchmod and fchmodat from the syscalls whitelist. Syscalls starts at line 52.


Applying the custom Seccomp profile:

docker container run --rm -it --security-opt seccomp=./default.json alpine sh
chmod +r /usr
Capabilities:

Dropping Capabilities:

docker container run --cap-drop=[CAPABILITY] [IMAGE] [CMD]

Test mknod:

docker container run --rm -it alpine sh
mknod /dev/random2 c 1 8

Disable mknod:

docker container run --rm -it --cap-drop=MKNOD alpine sh
mknod /dev/random2 c 1 8
Runtime privilege and Linux capabilities

Control Groups

Limiting CPU and memory:

docker container run -it --cpus=[VALUE] --memory=[VALUE][SIZE] --memory-swap [VALUE][SIZE] [IMAGE] [CMD]

Setting memory limits on a container:

docker container run -d --name resource-limits --cpus=".5" --memory=512M --memory-swap=1G rivethead42/weather-app

Inspect resource-limits:
docker container inspect resource-limits
Runtime constraints on resources More info on resource constraints


 Running Docker https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities
 Bench for Security  https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources


Running Docker Bench Security:

docker container run --rm -it --network host --pid host --userns host --cap-add audit_control \
    -e DOCKER_CONTENT_TRUST=$DOCKER_CONTENT_TRUST \
    -v /var/lib:/var/lib \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v /usr/lib/systemd:/usr/lib/systemd \
    -v /etc:/etc --label docker_bench_security \
    docker/docker-bench-security

  Docker Bench Security https://github.com/docker/docker-bench-security




--------

WORKING WITH SECRETS


We will start working with Docker Secrets to protect sensitive data, such as passwords and API Keys.

Docker secrets commands:

create: Create a secret from a file or STDIN as content
inspect: Display detailed information on one or more secrets
ls: List secrets
rm: Remove one or more secrets

Creating a secret:

STDIN | docker secret create [NAME] -

List secrets:

docker secret ls

Inspecting a secret:

docker secret inspect [NAME]

Using secrets:

docker service create --name [NAME] --secret [SECERT] [IMAGE]

Deleting a secret:

docker secret rm [NAME]

Setup environment:

mkdir Secrets
cd secrets

Create a secret using STDIN:
openssl rand -base64 20 | docker secret create my_secret_data -


Create a secret using a file:
openssl rand -base64 20 > secret.txt
docker secret create my_secret_data2 secret.txt

Create a service using a secret:
docker service create --name redis --secret my_secret_data redis:alpine

Find the node the service is running on:
docker service ps redis

Remove secret my_secret_data2:
docker secret rm my_secret_data2

Generate password files:
openssl rand -base64 20 > db_password.txt
openssl rand -base64 20 > db_root_password.txt

Create a Wordpress Stack:

vi docker-compose.yml

docker-compose.yml contents:

version: '3.1'

services:
   db:
     image: mysql:5.7
     volumes:
       - db_data:/var/lib/mysql
     networks:
       mysql_internal:
         aliases: ["db"]
     environment:
       MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password
       MYSQL_DATABASE: wordpress
       MYSQL_USER: wordpress
       MYSQL_PASSWORD_FILE: /run/secrets/db_password
     secrets:
       - db_root_password
       - db_password

   wordpress:
     depends_on:
       - db
     image: wordpress:latest
     networks:
       mysql_internal:
         aliases: ["wordpress"]
       wordpress_public:
     ports:
       - "8001:80"
     environment:
       WORDPRESS_DB_HOST: db:3306
       WORDPRESS_DB_USER: wordpress
       WORDPRESS_DB_PASSWORD_FILE: /run/secrets/db_password
     secrets:
       - db_password

secrets:
   db_password:
     file: db_password.txt
   db_root_password:
     file: db_root_password.txt

volumes:
    db_data:
networks:
  mysql_internal:
    driver: "overlay"
    internal: true
  wordpress_public:
    driver: "overlay"


Deploy stack:
        docker stack deploy --compose-file docker-compose.yml wp










             =====================================================

                     DOCKER CERTIFIED ASSOCIATE (DCA)
 
             =====================================================



Core Docker Concepts : 

1. DOCKER COMMUNITY EDITION INSTALLATION AND CONFIGURATION

  Docker Engine overview -https://docs.docker.com/install/




------

2.  INSTALLING DOCKER ON CENTOS


Relevant Documentation - https://docs.docker.com/install/linux/docker-ce/centos/


Install required packages:

sudo yum install -y device-mapper-persistent-data lvm2

Add the Docker CE repo:

sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo

Install the Docker CE packages and containerd.io:

sudo yum install -y docker-ce-18.09.5 docker-ce-cli-18.09.5 containerd.io

Start and enable the Docker service:

sudo systemctl start docker
sudo systemctl enable docker

Add cloud_user to the docker group, giving the user permission to run docker commands:

sudo usermod -a -G docker cloud_user

Log out and back in.

Test the installation by running a simple container:

docker run hello-world




-------

3.  INSTALLING DOCKER ON UBUNTU


Relevant Documentation -  https://docs.docker.com/install/linux/docker-ce/ubuntu/


Install required packages:

sudo apt-get update

sudo apt-get -y install \
  apt-transport-https \
  ca-certificates \
  curl \
  gnupg-agent \
  software-properties-common


Add the Docker GPG key and repo:

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

sudo apt-key fingerprint 0EBFCD88

sudo add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"

Install Docker CE packages:

sudo apt-get update
sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic containerd.io

Give cloud_user permission to run docker commands:
sudo usermod -a -G docker cloud_user

Log out and back in.

Test the installation by running a simple container:
docker run hello-world





------

4. SELECTING A STORAGE DRIVER

Relevant Documentation - https://docs.docker.com/storage/storagedriver/select-storage-driver/


Devicemapper               vs          Overlay

Devicemapper is best for    |  Overlay is best for reading. 
Writing. works on centos7   |  Works on centos 8 & above.   
& previous version          |


Get the current storage driver:
docker info

Set the storage driver explicitly by providing a flag to the Docker daemon:
sudo vi /usr/lib/systemd/system/docker.service

Edit the ExecStart line, adding the --storage-driver devicemapper flag:
ExecStart=/usr/bin/dockerd --storage-driver devicemapper ...

After any edits to the unit file, reload Systemd and restart Docker:
sudo systemctl daemon-reload
sudo systemctl restart docker

We can also set the storage driver explicitly using the daemon configuration file. This is the method that Docker recommends. Note that we cannot do this and pass the --storage-driver flag to the daemon at the same time:

sudo vi /etc/docker/daemon.json  --> creating a daemon.json file

Set the storage driver in the daemon configuration file:

{
  "storage-driver": "devicemapper"
}


Restart Docker after editing the file. It is also a good idea to make sure Docker is running properly after changing the configuration file:

sudo systemctl restart docker
sudo systemctl status docker




--------

5.  Running a Container


 https://docs.docker.com/engine/reference/run/


Run a simple container using the hello-world image:
docker run hello-world

Run a container using a specific image tag:
docker run nginx:1.15.11

Run a container with a command and arguments:
docker run busybox echo hello world!

Run an Nginx container customized with a variety of flags:
docker run -d --name nginx --restart unless-stopped -p 8080:80 --memory 500M --memory-reservation 256M nginx

List any currently running containers:
docker ps

List all containers, both running and stopped:
docker ps -a

Stop the Nginx container:
docker container stop nginx

Start a stopped container:
docker container start nginx

Delete a container (but it must be stopped first):
docker container rm nginx



---------

6.  UPGRADING THE DOCKER ENGINE:

Relevant Documentation -https://docs.docker.com/install/linux/docker-ce/ubuntu/#upgrade-docker-ce



Downgrade to a previous version:

sudo systemctl stop docker
sudo apt-get remove -y docker-ce docker-ce-cli
sudo apt-get update
sudo apt-get install -y docker-ce=5:18.09.4~3-0~ubuntu-bionic docker-ce-cli=5:18.09.4~3-0~ubuntu-bionic
docker version


Upgrade to a new version:

sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic
docker version



--------

7. CONFIGURING LOGGING DRIVERS (SPLUNK, JOURNALD, ETC.)

Relevant Documentation - https://docs.docker.com/config/containers/logging/configure/

Check the current default logging driver:

docker info | grep Logging


Edit daemon.json to set a new default logging driver configuration:

sudo vi /etc/docker/daemon.json
Add the configuration to daemon.json:

{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "15m"
  }
}


Restart docker after editing daemon.json:

sudo systemctl restart docker
Run a docker container, overriding the system default logging driver settings:

docker run --log-driver json-file --log-opt max-size=50m nginx




--------

8. INTRODUCTION TO DOCKER SWARM

Relevant Documentation - https://docs.docker.com/engine/swarm/key-concepts/


It provides orchestation,hig availability and scaling


--------

9. Configuring a Swarm Manager



Relevant Documentation -  https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/

Install Docker Engine on the Swarm Manager:

sudo apt-get update

sudo apt-get -y install \
  apt-transport-https \
  ca-certificates \
  curl \
  gnupg-agent \
  software-properties-common

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

sudo apt-key fingerprint 0EBFCD88

sudo add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"

sudo apt-get update

sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic containerd.io

sudo usermod -a -G docker cloud_user


Now initialize the swarm!

Note: Be sure to use the private IP (NOT the public IP) for the --advertise-addr:

docker swarm init --advertise-addr <swarm manager private IP>

This shows some basic information about the current status of the swarm:
docker info

List the current nodes in the swarm and their status:
docker node ls




---------

Install Docker Engine on both worker nodes:

sudo apt-get update

sudo apt-get -y install \
  apt-transport-https \
  ca-certificates \
  curl \
  gnupg-agent \
  software-properties-common

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

sudo apt-key fingerprint 0EBFCD88

sudo add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"

sudo apt-get update

sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic containerd.io

sudo usermod -a -G docker cloud_user
Get a join token from the manager. Run this command on the swarm manager:

docker swarm join-token worker
Now copy the docker swarm join command provided in the output and run it on both workers:

docker swarm join --token <token> <swarm manager private IP>:2377
On the swarm manager, verify that the two worker nodes have successfully joined:

docker node ls










































































































































































































































































































